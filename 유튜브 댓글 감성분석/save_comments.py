import os
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'sentiment_project.settings')
import django
django.setup()
from googleapiclient.discovery import build
from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline
import requests
from analysis.models import CommentSentiment

# Django ÏÑ§Ï†ï


# Íµ≠ÌöåÏùòÏõê Ïù¥Î¶Ñ ÏàòÏßë Ìï®Ïàò
def get_all_member_names(api_key):
    url = "https://open.assembly.go.kr/portal/openapi/nwvrqwxyaytdsfvhu"
    params = {
        'KEY': api_key,
        'Type': 'json',
        'pIndex': 1,
        'pSize': 300
    }
    response = requests.get(url, params=params)
    if response.status_code == 200:
        data = response.json()
        key = "nwvrqwxyaytdsfvhu"
        rows = data.get(key, [])[1].get("row", [])
        names = [member["HG_NM"] for member in rows if "HG_NM" in member]
        return names
    else:
        print("‚ùå Íµ≠ÌöåÏùòÏõê API ÏöîÏ≤≠ Ïã§Ìå®:", response.status_code)
        return []

# YouTube ÏÑ§Ï†ï
YOUTUBE_API_KEY = 'AIzaSyBNqTeD-YJ_5zSeqhKFY0s1Sno_ai2TtQ8'
youtube = build('youtube', 'v3', developerKey=YOUTUBE_API_KEY)

# ÎåìÍ∏Ä ÏàòÏßë Ìï®Ïàò
def fetch_comments(youtube, video_id, max_count=30):
    comments = []
    req = youtube.commentThreads().list(
        part='snippet',
        videoId=video_id,
        maxResults=max_count,
        textFormat='plainText'
    )
    res = req.execute()
    for item in res.get('items', []):
        text = item['snippet']['topLevelComment']['snippet']['textDisplay']
        if len(text.strip()) > 5:
            comments.append(text)
    return comments

# Í∞êÏÑ± Î∂ÑÏÑùÍ∏∞ ÏÑ§Ï†ï
model_name = "tabularisai/multilingual-sentiment-analysis"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)
analyzer = pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)

# Í∞êÏÑ± ÎùºÎ≤® Îßµ
sentiment_labels = {
    'Very Positive': 'Îß§Ïö∞ Í∏çÏ†ï',
    'Positive': 'Í∏çÏ†ï',
    'Neutral': 'Ï§ëÎ¶Ω',
    'Negative': 'Î∂ÄÏ†ï',
    'Very Negative': 'Îß§Ïö∞ Î∂ÄÏ†ï'
}

# Î∂ÑÏÑù Î∞è Ï†ÄÏû•
def analyze_and_store_comments(member_names):
    MIN_CONFIDENCE = 0.5

    for name in member_names:
        try:
            search = youtube.search().list(
                q=name,
                part='snippet',
                type='video',
                maxResults=1
            ).execute()

            if not search['items']:
                continue

            video = search['items'][0]
            video_id = video['id']['videoId']
            comments = fetch_comments(youtube, video_id)

            print(f"\nüéØ ÏùòÏõê: {name}, ÏòÅÏÉÅ: {video['snippet']['title']}, ÎåìÍ∏Ä Ïàò: {len(comments)}")

            for comment in comments:
                try:
                    result = analyzer(comment)[0]
                    sentiment = sentiment_labels.get(result['label'], result['label'])
                    confidence = round(result['score'], 2)

                    if confidence >= MIN_CONFIDENCE:
                        CommentSentiment.objects.create(
                            member_name=name,
                            comment_text=comment,
                            sentiment=sentiment,
                            sentiment_score=confidence
                        )
                        print(f"‚úÖ Ï†ÄÏû•: {sentiment} ({confidence}) - {comment[:30]}...")
                except Exception as e:
                    print(f"‚ö†Ô∏è Í∞êÏÑ± Î∂ÑÏÑù Ïã§Ìå®: {e}")
        except Exception as e:
            print(f"‚ùå YouTube Í≤ÄÏÉâ Ïò§Î•ò: {name} - {e}")

# Ïã§Ìñâ
OPEN_API_KEY = "1343ad8c9a584b86a2493aa90cf51060"
member_names = get_all_member_names(OPEN_API_KEY)
analyze_and_store_comments(member_names)
