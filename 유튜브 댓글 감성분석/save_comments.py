import os
import json
import re
import csv
from konlpy.tag import Okt
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError

# Django í™˜ê²½ ì„¤ì •
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'sentiment_project.settings')
import django
django.setup()
from analysis.models import CommentSentiment

# ì—¬ëŸ¬ API í‚¤ ìˆœí™˜ ì‚¬ìš©
API_KEYS = [
    "AIzaSyBY7zG5sVJ4VXlqd6JdCW4Q_29zNwox7V0",
    "AIzaSyCG9G9CSIHFmlRruVgshmU5-xGkhATlMZ0",
    "AIzaSyCF4WX5FGjd9-zsb9PPLvNZfe5z-6mESL8",
    "AIzaSyC5GxrmYvYHJXDQub_0JMHhc4ArQHhzyoA"
]
current_key_index = 0

def get_youtube_client():
    global current_key_index
    key = API_KEYS[current_key_index]
    current_key_index = (current_key_index + 1) % len(API_KEYS)
    return build('youtube', 'v3', developerKey=key)

# ê°ì„± ì‚¬ì „ ë¡œë“œ
with open("SentiWord_info.json", "r", encoding="utf-8") as f:
    senti_dict = {item["word_root"]: int(item["polarity"]) for item in json.load(f)}

okt = Okt()

def clean_text(text):
    return re.sub(r'[^\uAC00-\uD7A3a-zA-Z0-9\s]', '', text)

def analyze_sentiment(text):
    words = okt.morphs(clean_text(text))
    score = sum([senti_dict.get(word, 0) for word in words])
    sentiment = "ê¸ì •" if score > 0 else "ë¶€ì •" if score < 0 else "ì¤‘ë¦½"
    return sentiment, score

def fetch_comments(video_id, max_count=30, max_retries=5):
    """
    ì¢‹ì•„ìš”(ì¸ê¸°) ìˆœìœ¼ë¡œ ëŒ“ê¸€ 30ê°œ ìˆ˜ì§‘ (ì¤‘ë³µ ë°©ì§€ëŠ” DBì—ì„œ ì²˜ë¦¬)
    API í‚¤ ìˆœí™˜ ë° ì¿¼í„° ì´ˆê³¼/ì˜¤ë¥˜ ìë™ ì „í™˜
    """
    comments = []
    next_page_token = None
    tried = 0
    while len(comments) < max_count:
        youtube = get_youtube_client()
        try:
            req = youtube.commentThreads().list(
                part='snippet',
                videoId=video_id,
                maxResults=min(100, max_count - len(comments)),
                textFormat='plainText',
                order='relevance'
            )
            if next_page_token:
                req = req.pageToken(next_page_token)
            res = req.execute()
            for item in res.get('items', []):
                snippet = item['snippet']['topLevelComment']['snippet']
                text = snippet['textDisplay']
                like_count = snippet.get('likeCount', 0)
                if len(text.strip()) > 5:
                    comments.append((text, like_count))
                    if len(comments) >= max_count:
                        break
            next_page_token = res.get('nextPageToken')
            if not next_page_token:
                break
        except HttpError as e:
            tried += 1
            error_reason = str(e)
            print(f"â— API ì˜¤ë¥˜({error_reason}), ë‹¤ë¥¸ API í‚¤ë¡œ ì¬ì‹œë„({tried}/{max_retries})")
            if tried >= max_retries * len(API_KEYS):
                print("âŒ ëª¨ë“  API í‚¤ ì‹¤íŒ¨")
                break
            continue
        except Exception as e:
            print(f"â— ëŒ“ê¸€ ìš”ì²­ ì‹¤íŒ¨: {e}")
            break
    return comments

def analyze_and_store_from_csv(csv_path='video_ids.csv'):
    if not os.path.exists(csv_path):
        print("â— CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    updated_rows = []

    with open(csv_path, 'r', encoding='utf-8') as f:
        reader = list(csv.DictReader(f))
        for row in reader:
            if row.get("analyzed", "").lower() == 'true':
                updated_rows.append(row)
                continue

            name = row['member_name']
            video_id = row['video_id']
            title = row['video_title']
            if not video_id:
                updated_rows.append(row)
                continue

            comments = fetch_comments(video_id, max_count=30)
            print(f"\nğŸ¯ {name} | ì˜ìƒ: {title} | ëŒ“ê¸€ ìˆ˜: {len(comments)}")
            for comment, like_count in comments:
                # ì¤‘ë³µ ëŒ“ê¸€ ë°©ì§€
                if CommentSentiment.objects.filter(member_name=name, comment_text=comment).exists():
                    continue
                try:
                    sentiment, score = analyze_sentiment(comment)
                    CommentSentiment.objects.create(
                        member_name=name,
                        comment_text=comment,
                        sentiment=sentiment,
                        sentiment_score=score,
                        like_count=like_count  # ëª¨ë¸ì— like_count í•„ë“œê°€ ìˆì–´ì•¼ í•¨!
                    )
                    print(f"âœ… ì €ì¥: {sentiment} ({score}) | ì¢‹ì•„ìš”:{like_count} - {comment[:30]}...")
                except Exception as e:
                    print(f"âš ï¸ ì €ì¥ ì‹¤íŒ¨: {e}")

            row['analyzed'] = 'True'
            updated_rows.append(row)

    # ê°±ì‹ ëœ analyzed ìƒíƒœ ë‹¤ì‹œ ì €ì¥
    with open(csv_path, 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=['member_name', 'video_id', 'video_title', 'analyzed'])
        writer.writeheader()
        writer.writerows(updated_rows)

def main():
    analyze_and_store_from_csv()

if __name__ == "__main__":
    main()
