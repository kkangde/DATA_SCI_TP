import requests
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import torch.nn.functional as F

# ğŸ”‘ Twitter API Bearer Token ì„¤ì • (ì—¬ê¸°ì— ë³¸ì¸ì˜ í† í° ì…ë ¥)
bearer_token = "AAAAAAAAAAAAAAAAAAAAAH0X1AEAAAAAaRvJHfL65O7kcxn949jNiQbwB60%3DKGWr4sHmnLMLE6hQmkyLcIDB1FU6795XLC4U6rc3ZZ8IV0X0gL"

# ğŸ’¬ ê°ì„± ë¶„ì„ ëª¨ë¸ ì„¤ì •
model_name = "beomi/KcELECTRA-base-v2022"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)

# ğŸ§  ê°ì„± ë¶„ì„ í•¨ìˆ˜
def transformer_sentiment(text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, max_length=512)
    with torch.no_grad():
        outputs = model(**inputs)
        probs = F.softmax(outputs.logits, dim=1)
    labels = ["Negative", "Positive"]
    pred = torch.argmax(probs)
    return labels[pred]

# ğŸ¦ íŠ¸ìœ„í„° API ìš”ì²­ í•¨ìˆ˜
def search_tweets(query, max_results=10):
    url = f"https://api.twitter.com/2/tweets/search/recent?query={query}&max_results={max_results}&tweet.fields=lang"
    headers = {
        "Authorization": f"Bearer {bearer_token}",
        "User-Agent": "SentimentBot/1.0"  # âœ… í•œê¸€ ì—†ëŠ” User-Agent
    }

    try:
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        return response.json().get("data", [])
    except requests.exceptions.RequestException as e:
        print("âŒ Twitter API ìš”ì²­ ì‹¤íŒ¨:", e)
        return []

# ğŸš€ ì‹¤í–‰ ì˜ˆì œ
if __name__ == "__main__":
    query = "êµ­íšŒì˜ì› lang:ko"  # í•œêµ­ì–´ íŠ¸ìœ—ë§Œ ê²€ìƒ‰
    tweets = search_tweets(query)

    for tweet in tweets:
        text = tweet["text"]
        sentiment = transformer_sentiment(text)
        print(f"\níŠ¸ìœ—: {text}\nê°ì„± ë¶„ì„: {sentiment}")
