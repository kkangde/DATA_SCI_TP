import requests
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import torch.nn.functional as F

# ğŸ”‘ Twitter API Bearer Token ì„¤ì • (ë³¸ì¸ í† í°ìœ¼ë¡œ êµì²´!)
bearer_token = "ì—¬ê¸°ì—_ë³¸ì¸ì˜_Bearer_Token_ë¶™ì—¬ë„£ê¸°"

# ğŸ’¬ ê°ì„± ë¶„ì„ ëª¨ë¸ ì„¤ì • (ê³µê°œëœ í•œêµ­ì–´ ëª¨ë¸)
model_name = "beomi/KcELECTRA-base-v2022"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)

# ğŸ§  ê°ì„± ë¶„ì„ í•¨ìˆ˜
def transformer_sentiment(text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, max_length=512)
    outputs = model(**inputs)
    probs = F.softmax(outputs.logits, dim=1)
    labels = ["Negative", "Positive"]  # ì´ ëª¨ë¸ì€ ì´ì§„ ë¶„ë¥˜ (ë¶€ì •/ê¸ì •)
    pred = torch.argmax(probs)
    return labels[pred]

# ğŸ¦ íŠ¸ìœ„í„° API ìš”ì²­ í•¨ìˆ˜
def search_tweets(query, max_results=10):
    url = f"https://api.twitter.com/2/tweets/search/recent?query={query}&max_results={max_results}&tweet.fields=lang"
    headers = {
        "Authorization": f"Bearer {bearer_token}"
    }
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        return response.json().get("data", [])
    else:
        print("âŒ Twitter API Error:", response.status_code, response.text)
        return []

# ğŸš€ ì‹¤í–‰ ì˜ˆì œ
if __name__ == "__main__":
    query = "êµ­íšŒì˜ì› lang:ko"  # í•œêµ­ì–´ íŠ¸ìœ—ë§Œ ê²€ìƒ‰
    tweets = search_tweets(query)

    for tweet in tweets:
        text = tweet["text"]
        sentiment = transformer_sentiment(text)
        print(f"\níŠ¸ìœ—: {text}\nê°ì„± ë¶„ì„: {sentiment}")
